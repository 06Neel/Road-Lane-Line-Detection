{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Import required libraries:**\n",
        " Same as for image processing, you need to import the necessary libraries such as OpenCV, Numpy, and Matplotlib."
      ],
      "metadata": {
        "id": "1cfGCWJg1oIg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFVBO4Lr0wRr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the video:**\n",
        " You can use OpenCV's cv2.VideoCapture() function to load the video."
      ],
      "metadata": {
        "id": "WJVQ-d6-13Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Data/Detection_of_Road_Lane_Lines/lane_vid2.mp4')"
      ],
      "metadata": {
        "id": "OFdjf5CR1_iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing:**\n",
        " Same as for image processing, you need to preprocess each frame of the video."
      ],
      "metadata": {
        "id": "6mQ-I0Kl2Cm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Gaussian blur to reduce noise\n",
        "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "        # Apply Canny edge detection\n",
        "        edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "        # Select a region of interest\n",
        "        mask = np.zeros_like(edges)\n",
        "        height, width = edges.shape\n",
        "        polygon = np.array([[(0, height), (width / 2, height / 2), (width, height)]], np.int32)\n",
        "        cv2.fillPoly(mask, polygon, 255)\n",
        "        masked_edges = cv2.bitwise_and(edges, mask)\n",
        "\n",
        "        # Apply Hough transform to detect lines\n",
        "        lines = cv2.HoughLinesP(masked_edges, 1, np.pi / 180, 50, minLineLength=100, maxLineGap=50)\n",
        "\n",
        "        # Draw the detected lines on the original image\n",
        "        line_image = np.zeros_like(frame)\n",
        "        if lines is not None:\n",
        "            for line in lines:\n",
        "                x1, y1, x2, y2 = line[0]\n",
        "                cv2.line(line_image, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
        "\n",
        "        # Merge the original image with the detected lines\n",
        "        output = cv2.addWeighted(frame, 0.8, line_image, 1, 0)\n",
        "\n",
        "        # Convert the color space from BGR to RGB\n",
        "        output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Display the result using matplotlib\n",
        "        plt.imshow(output)\n",
        "        plt.show()\n",
        "\n",
        "        # Press Q on keyboard to exit\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    else:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "QBiuY1jB2HEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Region of interest:**\n",
        " Same as for image processing, you need to define a region of interest (ROI) on each frame of the video."
      ],
      "metadata": {
        "id": "p1SppLAv2HkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hough transform:**\n",
        " Same as for image processing, you need to perform Hough transform on each frame of the video to detect the lane lines."
      ],
      "metadata": {
        "id": "UOpgbq-72QJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Draw the lines:**\n",
        " Same as for image processing, you need to draw the lane lines on each frame of the video."
      ],
      "metadata": {
        "id": "5RMWQBGY2ivN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Display the final output:**\n",
        " You need to display each processed frame of the video in sequence. You can use OpenCV's cv2.imshow() function to display each frame, and cv2.waitKey() function to wait for a keypress before proceeding to the next frame."
      ],
      "metadata": {
        "id": "-BClECX52pXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, the approach for video lane detection is similar to that of image lane detection, but we need to process each frame of the video and display the processed frames in sequence to create a video output."
      ],
      "metadata": {
        "id": "CxshfUoy2xNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n"
      ],
      "metadata": {
        "id": "4dRldrek2vXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d133e4a-6727-4411-8a65-810bd1f88a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (4.7.0.68)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python-headless) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Data/Detection_of_Road_Lane_Lines/lane_vid2.mp4')\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Gaussian blur to reduce noise\n",
        "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "        # Apply Canny edge detection\n",
        "        edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "        # Select a region of interest\n",
        "        mask = np.zeros_like(edges)\n",
        "        height, width = edges.shape\n",
        "        polygon = np.array([[(0, height), (width / 2, height / 2), (width, height)]], np.int32)\n",
        "        cv2.fillPoly(mask, polygon, 255)\n",
        "        masked_edges = cv2.bitwise_and(edges, mask)\n",
        "\n",
        "        # Apply Hough transform to detect lines\n",
        "        lines = cv2.HoughLinesP(masked_edges, 1, np.pi / 180, threshold=50, minLineLength=100, maxLineGap=10)\n",
        "\n",
        "        # Draw the detected lines on the original image\n",
        "        line_image = np.zeros_like(frame)\n",
        "        if lines is not None:\n",
        "            for line in lines:\n",
        "                x1, y1, x2, y2 = line[0]\n",
        "                cv2.line(line_image, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
        "\n",
        "        # Merge the original image with the detected lines\n",
        "        output = cv2.addWeighted(frame, 0.8, line_image, 1, 0)\n",
        "\n",
        "        # Display the result\n",
        "        cv2_imshow(output)\n",
        "\n",
        "        # Press Q on keyboard to exit\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "MUtIiuTpg4Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Data/Detection_of_Road_Lane_Lines/lane_vid2.mp4')\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('output.avi', fourcc, 30, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Gaussian blur to reduce noise\n",
        "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "        # Apply Canny edge detection\n",
        "        edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "        # Select a region of interest\n",
        "        mask = np.zeros_like(edges)\n",
        "        height, width = edges.shape\n",
        "        polygon = np.array([[(0, height), (width / 2, height / 2), (width, height)]], np.int32)\n",
        "        cv2.fillPoly(mask, polygon, 255)\n",
        "        masked_edges = cv2.bitwise_and(edges, mask)\n",
        "\n",
        "        # Apply Hough transform to detect lines\n",
        "        lines = cv2.HoughLinesP(masked_edges, 1, np.pi / 180, threshold=50, minLineLength=100, maxLineGap=10)\n",
        "\n",
        "        # Draw the detected lines on the original image\n",
        "        line_image = np.zeros_like(frame)\n",
        "        if lines is not None:\n",
        "            for line in lines:\n",
        "                x1, y1, x2, y2 = line[0]\n",
        "                cv2.line(line_image, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
        "\n",
        "        # Merge the original image with the detected lines\n",
        "        output = cv2.addWeighted(frame, 0.8, line_image, 1, 0)\n",
        "\n",
        "        # Write the frame to the output video\n",
        "        out.write(output)\n",
        "\n",
        "        # Display the result\n",
        "        cv2_imshow(output)\n",
        "\n",
        "        # Press Q on keyboard to exit\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close all windows\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "PvwgV8suiw4i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}